{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from src import transforms as T\n",
    "\n",
    "from src.unet.unet import Unet\n",
    "from src.unet.unet_module import UnetModule\n",
    "from src.mri_module import MriModule\n",
    "from src.subsample import create_mask_for_mask_type, RandomMaskFunc\n",
    "from src.mri_data import CombinedSliceDataset, AnnotatedSliceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x141ba7e20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lsantos/Projects/fastMRI/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/lsantos/Projects/fastMRI/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1435, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    }
   ],
   "source": [
    "def load_model_from_checkpoint(checkpoint_path, hparams_file=None):\n",
    "    print(f'Loading model from checkpoint: {checkpoint_path}')\n",
    "    model = UnetModule.load_from_checkpoint(checkpoint_path, hparams_file=hparams_file, device='mps')\n",
    "    model.eval()\n",
    "    print(f'Model loaded from checkpoint: {checkpoint_path}')\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    from tqdm import tqdm\n",
    "    metric = 0\n",
    "    metrics = dict()\n",
    "    roi_len = 1\n",
    "    metrics['val_loss'] = 0\n",
    "    metrics['image_l1_loss'] = 0\n",
    "    metrics['image_ssim_loss'] = 0\n",
    "    metrics['roi_l1_loss'] = 0\n",
    "    metrics['roi_ssim_loss'] = 0\n",
    "    \n",
    "    print('Evaluating model...')\n",
    "    for batch in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            output = model.validation_step_comparison(batch, batch_idx=0)\n",
    "            metrics['val_loss'] += output['val_loss'].item()\n",
    "            metrics['image_l1_loss'] += output['image_l1_loss'].item()\n",
    "            metrics['image_ssim_loss'] += output['image_ssim_loss'].item()\n",
    "            if not (metrics['roi_l1_loss'] == 0 and metrics['roi_ssim_loss'] == 0):\n",
    "                roi_len += 1              \n",
    "                metrics['roi_l1_loss'] += output['roi_l1_loss']\n",
    "                metrics['roi_ssim_loss'] += output['roi_ssim_loss']\n",
    "            metric += output['val_loss']\n",
    "    metric /= len(dataloader)\n",
    "    metrics['val_loss'] /= len(dataloader)\n",
    "    metrics['image_l1_loss'] /= len(dataloader)\n",
    "    metrics['image_ssim_loss'] /= len(dataloader)\n",
    "    metrics['roi_l1_loss'] /= roi_len\n",
    "    metrics['roi_ssim_loss'] /= roi_len\n",
    "    metrics['roi_len'] = roi_len\n",
    "    return metric, metrics\n",
    "\n",
    "\n",
    "configs = {\n",
    "    'data_dir': 'data/singlecoil_val',\n",
    "    'checkpoints': [\n",
    "        'logs/unet/unet_roi/checkpoints/epoch=9-step=347420.ckpt',\n",
    "        'logs/unet/unet_l1/checkpoints/epoch=9-step=347420.ckpt',\n",
    "    ],\n",
    "    'batch_size': 1,\n",
    "    'num_workers': 4,\n",
    "    'challenge':\"singlecoil\",\n",
    "    'mask_type':\"random\",  # \"random\" or \"equispaced_fraction\"\n",
    "    'center_fractions':[0.08],  # number of center lines to use in the mask\n",
    "    'accelerations':[4],  # acceleration rates to use for the mask\n",
    "}\n",
    "\n",
    "\n",
    "mask = create_mask_for_mask_type(\n",
    "    configs['mask_type'], configs['center_fractions'], configs['accelerations']\n",
    ")\n",
    "\n",
    "val_transform = T.UnetDataTransform(configs['challenge'], mask_func=mask)\n",
    "\n",
    "# validation_dataset = CombinedSliceDataset(\n",
    "#     roots=[Path(configs['data_dir'])],\n",
    "#     challenges=['singlecoil'],\n",
    "#     transforms=[val_transform]\n",
    "# )\n",
    "\n",
    "validation_dataset = AnnotatedSliceDataset(\n",
    "    root=Path(configs['data_dir']),\n",
    "    transform=val_transform,\n",
    "    challenge=configs['challenge'],\n",
    "    use_dataset_cache=False,\n",
    "    raw_sample_filter=None,\n",
    "    subsplit='knee',\n",
    "    multiple_annotation_policy='all',\n",
    ")\n",
    "\n",
    "gen = torch.Generator().manual_seed(42)\n",
    "# Use the line below to get a smaller validation set\n",
    "samples = 150\n",
    "validation_dataset = random_split(validation_dataset, [samples, len(validation_dataset) - samples], generator=gen)[0]\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=configs['batch_size'],\n",
    "    num_workers=configs['num_workers'],\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_annot = 0\n",
    "for i in range(len(validation_dataset)):\n",
    "    try:\n",
    "        if validation_dataset[i].annotations is not None:\n",
    "            if validation_dataset[i].annotations[0]['fname'] != \"\":\n",
    "                has_annot += 1\n",
    "    except AttributeError: \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsantos/Projects/fastMRI/.venv/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoint: logs/unet/unet_roi/checkpoints/epoch=9-step=347420.ckpt\n",
      "Model loaded from checkpoint: logs/unet/unet_roi/checkpoints/epoch=9-step=347420.ckpt\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m checkpoint_path \u001b[38;5;129;01min\u001b[39;00m configs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoints\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m load_model_from_checkpoint(checkpoint_path)\n\u001b[0;32m----> 5\u001b[0m     val_metric, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     results[checkpoint_path] \u001b[38;5;241m=\u001b[39m val_metric\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, other metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 21\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     18\u001b[0m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroi_ssim_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluating model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     23\u001b[0m         output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mvalidation_step_comparison(batch, batch_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/fastMRI/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/fastMRI/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/fastMRI/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/fastMRI/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1053\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1051\u001b[0m     current_device \u001b[38;5;241m=\u001b[39m custom_device_mod\u001b[38;5;241m.\u001b[39mcurrent_device()\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1053\u001b[0m     current_device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# choose cuda for default\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m pin_memory_thread \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread(\n\u001b[1;32m   1055\u001b[0m     target\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39m_pin_memory_loop,\n\u001b[1;32m   1056\u001b[0m     args\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_result_queue, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_queue,\n\u001b[1;32m   1057\u001b[0m           current_device,\n\u001b[1;32m   1058\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread_done_event, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device))\n\u001b[1;32m   1059\u001b[0m pin_memory_thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/fastMRI/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:878\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/Projects/fastMRI/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for checkpoint_path in configs['checkpoints']:\n",
    "    model = load_model_from_checkpoint(checkpoint_path)\n",
    "    val_metric, metrics = evaluate_model(model, validation_loader)\n",
    "    results[checkpoint_path] = val_metric\n",
    "    print(f\"Model: {checkpoint_path}, Validation Metric: {val_metric}, other metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036901235580444336"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of all models:\n",
      "Model: logs/unet/unet_roi/checkpoints/epoch=9-step=347420.ckpt, Validation Metric: 0.003733583688735962\n",
      "Model: logs/unet/unet_l1/checkpoints/epoch=9-step=347420.ckpt, Validation Metric: 0.0036901235580444336\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary of all models:\")\n",
    "for checkpoint_path, val_metric in results.items():\n",
    "    print(f\"Model: {checkpoint_path}, Validation Metric: {val_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logs/unet/unet_roi/checkpoints/epoch=9-step=347420.ckpt': 0.003733583688735962,\n",
       " 'logs/unet/unet_l1/checkpoints/epoch=9-step=347420.ckpt': 0.0036901235580444336}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
