{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastmri\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pathlib\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from src.subsample import create_mask_for_mask_type, RandomMaskFunc\n",
    "from src import transforms as T\n",
    "from src.mri_data import fetch_dir\n",
    "from src.data_module import FastMriDataModule, AnnotatedSliceDataset\n",
    "from src.unet.unet_module import UnetModule\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "tensorboard = pl_loggers.TensorBoardLogger('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "path_config = pathlib.Path(\"fastmri_dirs.yaml\")\n",
    "\n",
    "version_name = \"unet\" # one of \"unet\", \"unet_attn\", \"unet_ssim\", \"unet_attn_ssim\"\n",
    "\n",
    "\n",
    "# Default parameter values\n",
    "only_annotated = False\n",
    "attn_layer = False\n",
    "metric = \"l1\"\n",
    "use_roi = False\n",
    "use_attention_gates = False  # New parameter\n",
    "\n",
    "# Configure model variants\n",
    "if version_name == \"unet\":\n",
    "    pass  # Using defaults above\n",
    "elif version_name == \"unet_roi\":\n",
    "    use_roi = True\n",
    "elif version_name == \"unet_attn\":\n",
    "    attn_layer = True\n",
    "elif version_name == \"unet_attn_roi\":\n",
    "    attn_layer = True\n",
    "    use_roi = True\n",
    "elif version_name == \"unet_ssim\":\n",
    "    metric = \"ssim\"\n",
    "    use_roi = True\n",
    "elif version_name == \"unet_attn_ssim\":\n",
    "    attn_layer = True\n",
    "    metric = \"ssim\"\n",
    "    use_roi = True\n",
    "elif version_name == \"unet_annot_only\":\n",
    "    only_annotated = True\n",
    "elif version_name == \"unet_roi_annot_only\":\n",
    "    use_roi = True\n",
    "    only_annotated = True\n",
    "# New configurations for attention gates\n",
    "elif version_name == \"unet_attention_gates\":\n",
    "    use_attention_gates = True\n",
    "    use_roi = True\n",
    "elif version_name == \"unet_attention_gates_attn\":\n",
    "    use_attention_gates = True\n",
    "    attn_layer = True\n",
    "    use_roi = True\n",
    "elif version_name == \"unet_attention_gates_ssim\":\n",
    "    use_attention_gates = True\n",
    "    metric = \"ssim\"\n",
    "    use_roi = True\n",
    "\n",
    "# Build descriptive version name\n",
    "version_name = f\"{version_name}_{metric}\" + \\\n",
    "              (\"_roi\" if use_roi else \"\") + \\\n",
    "              (\"_attn\" if attn_layer else \"\") + \\\n",
    "              (\"_agate\" if use_attention_gates else \"\") + \\\n",
    "              (\"_annot\" if only_annotated else \"\")\n",
    "\n",
    "\n",
    "configs = dict(\n",
    "    challenge=\"singlecoil\",\n",
    "    num_gpus=1,\n",
    "    backend=\"mps\",\n",
    "    batch_size=8,\n",
    "    data_path=fetch_dir(\"knee_path\", path_config),\n",
    "    default_root_dir=fetch_dir(\"log_path\", path_config) / \"unet\" / version_name,\n",
    "    mode=\"train\",  # \"train\" or \"test\"\n",
    "    mask_type=\"random\",  # \"random\" or \"equispaced_fraction\"\n",
    "    center_fractions=[0.08],  # number of center lines to use in the mask\n",
    "    accelerations=[4],  # acceleration rates to use for the mask\n",
    "    # model parameters\n",
    "    in_chans=1,\n",
    "    out_chans=1,\n",
    "    #chans=32,\n",
    "    chans=64,\n",
    "    #num_pool_layers=4,\n",
    "    num_pool_layers=3,\n",
    "    drop_prob=0.0,\n",
    "    lr=0.001,\n",
    "    lr_step_size=40,\n",
    "    lr_gamma=0.1,\n",
    "    weight_decay=0.0,\n",
    "    max_epochs=10,\n",
    "    metric=metric,\n",
    "    roi_weight=0.5,\n",
    "    attn_layer=attn_layer,\n",
    "    use_roi=use_roi,\n",
    "    only_annotated=only_annotated,\n",
    "    use_attention_gates=use_attention_gates,\n",
    ")\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# mask for transforming the input data\n",
    "mask = create_mask_for_mask_type(\n",
    "    configs['mask_type'], configs['center_fractions'], configs['accelerations']\n",
    ")\n",
    "\n",
    "# random masks for train, fixed masks for val\n",
    "train_transform = T.UnetDataTransform(configs['challenge'], mask_func=mask, use_seed=False)\n",
    "val_transform = T.UnetDataTransform(configs['challenge'], mask_func=mask)\n",
    "test_transform = T.UnetDataTransform(configs['challenge'])\n",
    "\n",
    "# create a data module\n",
    "data_module = FastMriDataModule(\n",
    "    data_path=configs['data_path'],\n",
    "    challenge=configs['challenge'],\n",
    "    train_transform=train_transform,\n",
    "    val_transform=val_transform,\n",
    "    test_transform=test_transform,\n",
    "    test_path=None,\n",
    "    batch_size=configs['batch_size'],\n",
    "    num_workers=10,\n",
    "    only_annotated=configs['only_annotated']\n",
    ")\n",
    "\n",
    "# create a model\n",
    "model = UnetModule(\n",
    "    in_chans=configs['in_chans'],\n",
    "    out_chans=configs['out_chans'],\n",
    "    chans=configs['chans'],\n",
    "    num_pool_layers=configs['num_pool_layers'],\n",
    "    drop_prob=configs['drop_prob'],\n",
    "    lr=configs['lr'],\n",
    "    lr_step_size=configs['lr_step_size'],\n",
    "    lr_gamma=configs['lr_gamma'],\n",
    "    weight_decay=configs['weight_decay'],\n",
    "    metric=configs['metric'],\n",
    "    roi_weight=configs['roi_weight'],\n",
    "    attn_layer=configs['attn_layer'],\n",
    "    use_roi=configs['use_roi'],\n",
    "    use_attention_gates=configs['use_attention_gates'],\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    pl.callbacks.ModelCheckpoint(\n",
    "        # dirpath=configs['default_root_dir'],\n",
    "        dirpath=configs['default_root_dir'] / \"checkpoints\",\n",
    "        # monitor=\"val_loss\",\n",
    "        monitor=\"validation_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "        save_last=True,\n",
    "        verbose=True,\n",
    "    ),\n",
    "    pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "]\n",
    "\n",
    "# create a trainer\n",
    "trainer = pl.Trainer(\n",
    "    devices=configs['num_gpus'],\n",
    "    max_epochs=configs['max_epochs'],\n",
    "    default_root_dir=configs['default_root_dir'],\n",
    "    accelerator=configs['backend'],\n",
    "    callbacks=callbacks,\n",
    "    logger=tensorboard,\n",
    "    profiler='simple'\n",
    ")\n",
    "\n",
    "#if args.resume_from_checkpoint is None:\n",
    "#    ckpt_list = sorted(checkpoint_dir.glob(\"*.ckpt\"), key=os.path.getmtime)\n",
    "  #  if ckpt_list:\n",
    " #       args.resume_from_checkpoint = str(ckpt_list[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aRun the line of code to follow the training process of the model. The training process will be displayed in the TensorBoard:\n",
    "\n",
    "tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "annotations generate multiple images: 48450 train samples\n",
    "annotations generate a single image: 41877 train samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsantos/Projects/fastMRI/.venv/lib/python3.13/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory logs/unet/unet_l1/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name             | Type                 | Params\n",
      "----------------------------------------------------------\n",
      "0 | NMSE             | DistributedMetricSum | 0     \n",
      "1 | SSIM             | DistributedMetricSum | 0     \n",
      "2 | PSNR             | DistributedMetricSum | 0     \n",
      "3 | ValLoss          | DistributedMetricSum | 0     \n",
      "4 | TotExamples      | DistributedMetricSum | 0     \n",
      "5 | TotSliceExamples | DistributedMetricSum | 0     \n",
      "6 | unet             | Unet                 | 124 M \n",
      "----------------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "496.375   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf41ef82a204eb59e28ce468aa44fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3857b43f84d143dfba3f762d7a70e198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lsantos/Projects/fastMRI/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 320, 320))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7844147 with attention\n",
    "7756097 without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_list = sorted(configs['default_root_dir'].glob(\"*.ckpt\"), key=os.path.getmtime)\n",
    "if ckpt_list:\n",
    "    resume_from_checkpoint = str(ckpt_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abaraldo/Documents/GitHub/fastMRI/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:55: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v2.0. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    devices=configs['num_gpus'],\n",
    "    max_epochs=configs['max_epochs'],\n",
    "    default_root_dir=configs['default_root_dir'],\n",
    "    accelerator=configs['backend'],\n",
    "    callbacks=callbacks,\n",
    "    logger=tensorboard,\n",
    "    resume_from_checkpoint=resume_from_checkpoint,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take one sample from data_module\n",
    "#data_module.setup()\n",
    "sample = next(iter(data_module.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': [''],\n",
       " 'slice': [''],\n",
       " 'study_level': [''],\n",
       " 'x': tensor([-1]),\n",
       " 'y': tensor([-1]),\n",
       " 'width': tensor([-1]),\n",
       " 'height': tensor([-1]),\n",
       " 'label': ['']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.annotation['x'].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = sample.target.shape\n",
    "annotation = {'fname': 'file1000001',\n",
    "    'slice': 15,\n",
    "    'study_level': 'No',\n",
    "    'x': 117,\n",
    "    'y': 146,\n",
    "    'width': 20,\n",
    "    'height': 12,\n",
    "    'label': 'Bone- Subchondral edema'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones(shape)\n",
    "x, y, w, h = annotation['x'], annotation['y'], annotation['width'], annotation['height']\n",
    "if x >= 0 and y >= 0 and w > 0 and h > 0:\n",
    "    mask[..., y:y+h, x:x+w] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 158, 117, 137)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y, y+h, x, x+w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = fetch_dir(\"knee_path\", path_config) / f\"{configs['challenge']}_train\"\n",
    "dataset = AnnotatedSliceDataset(\n",
    "    root=data_path,\n",
    "    transform=val_transform,\n",
    "    challenge=configs['challenge'],\n",
    "    use_dataset_cache=False,\n",
    "    raw_sample_filter=None,\n",
    "    subsplit='knee',\n",
    "    multiple_annotation_policy='all',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset.__getitem__(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fname': 'file1000001',\n",
       " 'slice': 15,\n",
       " 'study_level': 'No',\n",
       " 'x': 117,\n",
       " 'y': 146,\n",
       " 'width': 20,\n",
       " 'height': 12,\n",
       " 'label': 'Bone- Subchondral edema'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.mri_data.AnnotatedSliceDataset"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./dataset_cache.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
